{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Spark session and load csv data #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "# Load the Stack Overflow survey response CSV file into a DataFrame\n",
    "soDf = spark.read.csv(\"C:\\\\Users\\\\Phil.Austin\\\\OneDrive - Telefonica Tech UK Limited\\\\survey_results_public.csv\", header=True, inferSchema=True)\n",
    "\n",
    "# Show the first few rows of the DataFrame\n",
    "soDf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soDf.createOrReplaceTempView(\"so_data\")\n",
    "\n",
    "grpDf = spark.sql(\"\"\"\n",
    "                    SELECT \n",
    "                        Age, \n",
    "                        COUNT(*) AS NumberOfResponses \n",
    "                    FROM so_data \n",
    "                    GROUP BY Age \n",
    "                    ORDER BY COUNT(*) DESC\n",
    "                \"\"\")\n",
    "\n",
    "grpDf.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Salaries are in different currencies #\n",
    "\n",
    "## Which you can see in Data Wrangler... ##\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load currency conversions\n",
    "currencyConvDf = spark.read.csv(\"average_csv_2024-3.csv\", header=True, inferSchema=True)\n",
    "\n",
    "currencyConvDf.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add a Currency Code column to the SO dataframe #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Add a new column 'CurrencyCode' to soDf that contains the first three letters of 'Currency'\n",
    "soDf = soDf.withColumn(\"CurrencyCode\", F.expr(\"substring(Currency, 1, 3)\"))\n",
    "\n",
    "soDf.filter(soDf.Currency != 'NA').select(soDf[\"Currency\"], soDf[\"CurrencyCode\"]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert Compensation into GBP #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import DecimalType\n",
    "\n",
    "# Join soDf to currencyConvDf where currencyConvDf.CurrencyCode = soDf.Currency Code\n",
    "conversionDf = soDf.join(\n",
    "    currencyConvDf,\n",
    "    soDf[\"CurrencyCode\"] == currencyConvDf[\"Currency Code\"],\n",
    "    \"inner\"\n",
    "). \\\n",
    "    select(soDf[\"Country\"], \\\n",
    "           soDf[\"CompTotal\"], \\\n",
    "           soDf[\"LanguageHaveWorkedWith\"], \\\n",
    "           currencyConvDf[\"Sterling value of Currency Unit £\"])\n",
    "\n",
    "# convert total compensation into GBP\n",
    "conversionDf = conversionDf.withColumn(\"CompTotalInGBP\", \n",
    "                    F.col(\"CompTotal\") * F.col(\"Sterling value of Currency Unit £\"))\n",
    "\n",
    "\n",
    "# Split the LanguagesWorkedWith column on the ; character and explode it\n",
    "explodedDf = conversionDf.withColumn(\n",
    "    \"Language\",\n",
    "    F.explode(F.split(F.col(\"LanguageHaveWorkedWith\"), \";\"))\n",
    ")\n",
    "\n",
    "explodedDf.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# And the winner is... #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Filter out rows where CompTotalInGBP is 0 or null\n",
    "filteredDf = explodedDf.filter((F.col(\"CompTotalInGBP\") != 0) \\\n",
    "                               & (F.col(\"CompTotalInGBP\").isNotNull()) \n",
    "                               )   \n",
    "\n",
    "# Aggregate median CompTotalInGBP by Language and show the top 10\n",
    "aggregatedDf = filteredDf.groupBy(\"Language\").\\\n",
    "                agg(F.median(\"CompTotalInGBP\").alias(\"Median Compensation In GBP\")).\\\n",
    "                        orderBy(F.desc(\"Median Compensation In GBP\")).\\\n",
    "                            limit(20)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregatedDf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out rows where CompTotalInGBP is 0 or null\n",
    "filteredDf = explodedDf.filter((F.col(\"CompTotalInGBP\") != 0) \\\n",
    "                               & (F.col(\"CompTotalInGBP\").isNotNull()) \\\n",
    "                                   & (F.col(\"Country\") == \"United Kingdom of Great Britain and Northern Ireland\"))   \n",
    "\n",
    "# Aggregate median CompTotalInGBP by Language and show the top 10\n",
    "aggregatedDf = filteredDf.groupBy(\"Language\").\\\n",
    "                agg(F.median(\"CompTotalInGBP\").alias(\"Median Compensation In GBP\")).\\\n",
    "                        orderBy(F.desc(\"Median Compensation In GBP\")).\\\n",
    "                            limit(20)\n",
    "\n",
    "aggregatedDf.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dataengforfree_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
